import logging

import subprocess
from typing import Dict, Any

from benchmarks.base_benchmark import BaseBenchmark
from benchmarks.command import Command, CommandResult
from benchmarks.cargo_helper import build_example
from omegaconf import DictConfig

from benchmarks.benchmark_config_parser import BenchmarkConfigParser

log = logging.getLogger(__name__)


class PrefetchBenchmark(BaseBenchmark):
    def __init__(self, cfg: DictConfig, metadata: Dict[str, Any]):
        self.metadata = metadata
        self.config_parser = BenchmarkConfigParser(cfg)
        self.common_config = self.config_parser.get_common_config()
        self.prefetch_config = self.config_parser.get_prefetch_config()

    def setup(self) -> Dict[str, Any]:
        log.info("Compiling prefetch_benchmark example...")
        self.executable_path = build_example("prefetch_benchmark")
        log.info(f"Prefetch benchmark executable ready at: {self.executable_path}")

        return self.metadata

    def get_command(self) -> Command:
        subprocess_args = [
            self.executable_path,
            self.common_config['s3_bucket'],
        ]

        object_size = self.common_config['object_size_in_gib']
        size_gib = str(object_size)
        app_workers = self.common_config['application_workers']

        # Check if objects are specified or if we have to fall back to objects
        # generated by fio.
        objects = self.common_config['s3_keys']
        if not objects:
            objects = self.config_parser.default_object_keys(app_workers, size_gib)

        if len(objects) >= app_workers:
            for i in range(app_workers):
                subprocess_args.append(objects[i])
        else:
            raise ValueError("Seeing fewer objects than app workers. So cannot proceed with the run.")

        region = self.common_config["region"]
        subprocess_args.extend(["--region", region])

        if (max_throughput := self.common_config['max_throughput_gbps']) is not None:
            subprocess_args.extend(["--maximum-throughput-gbps", str(max_throughput)])

        if (max_memory_target := self.prefetch_config['max_memory_target']) is not None:
            subprocess_args.extend(["--max-memory-target", str(max_memory_target)])

        if (read_part_size := self.common_config['read_part_size']) is not None:
            subprocess_args.extend(["--part-size", str(read_part_size)])

        read_size = self.common_config['read_size']
        subprocess_args.extend(["--read-size", str(read_size)])

        for interface in self.common_config['network_interfaces']:
            subprocess_args.extend(["--bind", interface])

        if (run_time := self.common_config['run_time']) is not None:
            subprocess_args.extend(["--max-duration", str(run_time)])

        subprocess_args.extend(["--output-file", "prefetch-output.json"])

        prefetch_env = {}
        if not self.common_config['download_checksums']:
            prefetch_env["EXPERIMENTAL_MOUNTPOINT_NO_DOWNLOAD_INTEGRITY_VALIDATION"] = "ON"

        log.info("Prefetch benchmark command prepared with args: %s", subprocess_args)

        return Command(args=subprocess_args, env=prefetch_env, capture_output=True)

    def post_process(self, result: CommandResult) -> Dict[str, Any]:
        if result.returncode != 0:
            log.error(f"Prefetch benchmark failed with exit code {result.returncode}")
            if result.stderr:
                log.error(f"Error output: {result.stderr}")
            raise subprocess.CalledProcessError(result.returncode, ["prefetch_benchmark"])

        log.info("Prefetch benchmark completed successfully.")
        self.metadata["prefetch_output_file"] = "prefetch-output.json"
        return self.metadata

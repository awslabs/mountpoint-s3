# This file (and others in `conf/`) specify some static parameters,
# as well as some which will be 'swept' over for experiments.

defaults:
  - _self_

s3_bucket: ???
s3_prefix: !!null

read_part_size: !!null
write_part_size: 16777216 # to allow for uploads of 100GiB

metadata_ttl: "indefinite"

fio_benchmarks:
  - sequential_read

# Path to Mountpoint binary. Recommended to use an absolute path.
mountpoint_binary: !!null
mountpoint_debug: false
mountpoint_debug_crt: false

# No configuration out of the box, use defaults.
network:
  interface_names: []
  maximum_throughput_gbps: !!null

# For overriding upload checksums configured for Mountpoint. Passed as `--upload-checksums` argument.
upload_checksums: !!null

# For overriding fuse max_background and congestion threshold setttings
# environment variables
mountpoint_max_background: !!null
mountpoint_congestion_threshold: !!null

# For monitoring network bandwidth
with_bwm: false

# Works automatically ONLY where this script manages compilation. It has no effect if `mountpoint_binary` is set.
stub_mode: "off" # fs_handler, s3_client

iterations: 1

# Define defaults for these columns, but script will run as MULTIRUN by default
fuse_threads: !!null
application_workers: 1
direct_io: false
fio_benchmark: "${fio_benchmarks[0]}"
fio_io_engine: "psync"
iteration: 0

hydra:
  help:
    app_name: "Mountpoint sequential read experiment runner"
  mode: MULTIRUN
  job:
    chdir: true
  sweeper:
    params:
      # Maximum number of FUSE threads for Mountpoint. Passed as `--max-threads` argument.
      'fuse_threads': 16, 32, 64, 128
      # Number of processes that will be interacting with the file.
      'application_workers': 1, 4, 8, 16, 32, 64, 128, 256
      # Configure if application should use Direct IO, skipping the Linux page cache
      'direct_io': false, true
      # Don't touch the params below, they are based on settings above.
      'fio_benchmark': "${join:',', ${fio_benchmarks}}"
      'iteration': "range(${iterations})"
